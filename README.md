# Benchmark LLM

The script `workflow.ipynb` helps reproduce the data presented in the article [From Codebooks to Promptbooks: Extracting Information from Text with Generative Large Language Models](https://osf.io/preprints/socarxiv/wjvfq_v1).

The protocol is detailed in the notebook. Input files are obtained with information extraction by different LLMs.

Requirements : `pip install -r requirements.txt`
