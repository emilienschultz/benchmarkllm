# Benchmark LLM

The script `workflow.ipynb` allows the reproducibility of the comparison between information extraction with LLMs and ground truth used in the article [From Codebooks to Promptbooks: Extracting Information from Text with Generative Large Language Models](https://osf.io/preprints/socarxiv/wjvfq_v1).

The protocol is detailed in the notebook. Input files are obtained with information extraction by different LLMs.

Requirements : `pip install -r requirements.txt`